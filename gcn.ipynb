{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c4da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    \"\"\"\n",
    "        GCN layer\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Dimension of the input\n",
    "            output_dim (int): Dimension of the output (a softmax distribution)\n",
    "            A (torch.Tensor): 2D adjacency matrix\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, output_dim: int, A: torch.Tensor):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.A = A\n",
    "\n",
    "        # A_hat = A + I\n",
    "        self.A_hat = self.A + torch.eye(self.A.size(0))\n",
    "\n",
    "        # Create diagonal degree matrix D\n",
    "        self.ones = torch.ones(input_dim, input_dim)\n",
    "        self.D = torch.matmul(self.A.float(), self.ones.float())\n",
    "\n",
    "        # Extract the diagonal elements\n",
    "        self.D = torch.diag(self.D)\n",
    "\n",
    "        # Create a new tensor with the diagonal elements and zeros elsewhere\n",
    "        self.D = torch.diag_embed(self.D)\n",
    "        \n",
    "        # Create D^{-1/2}\n",
    "        self.D_neg_sqrt = torch.diag_embed(torch.diag(torch.pow(self.D, -0.5)))\n",
    "        \n",
    "        # Initialise the weight matrix as a parameter\n",
    "        self.W = nn.Parameter(torch.rand(input_dim, output_dim))\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "\n",
    "        # D^-1/2 * (A_hat * D^-1/2)\n",
    "        support_1 = torch.matmul(self.D_neg_sqrt, torch.matmul(self.A_hat, self.D_neg_sqrt))\n",
    "        \n",
    "        # (D^-1/2 * A_hat * D^-1/2) * (X * W)\n",
    "        support_2 = torch.matmul(support_1, torch.matmul(X, self.W))\n",
    "        \n",
    "        # ReLU(D^-1/2 * A_hat * D^-1/2 * X * W)\n",
    "        H = F.relu(support_2)\n",
    "\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.9300,  4.4642],\n",
      "        [13.9212, 12.4652],\n",
      "        [16.1021, 14.7444]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "input_dim = 3  # Assuming the input dimension is 3\n",
    "output_dim = 2  # Assuming the output dimension is 2\n",
    "\n",
    "# Example adjacency matrix\n",
    "A = torch.tensor([[1., 0., 0.],\n",
    "                    [0., 1., 1.],\n",
    "                    [0., 1., 1.]])  \n",
    "\n",
    "# Create the GCN Layer\n",
    "gcn_layer = GCNLayer(input_dim, output_dim, A)\n",
    "\n",
    "# Example input feature matrix\n",
    "X = torch.tensor([[1., 2., 3.],\n",
    "                    [4., 5., 6.],\n",
    "                    [7., 8., 9.]])\n",
    "\n",
    "# Forward pass\n",
    "output = gcn_layer(X)\n",
    "\n",
    "print(output)\n",
    "# tensor([[ 6.3438,  5.8004],\n",
    "#         [13.3558, 13.7459],\n",
    "#         [15.5052, 16.0948]], grad_fn=<ReluBackward0>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
